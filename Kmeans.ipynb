{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "import pickle\n",
    "from tqdm.notebook import tqdm\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch\n",
    "from sklearn.cluster import KMeans\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "pd.set_option('display.max_columns', 5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this notebook is to cluster instances into similar groups so that contrastive loss can effectively learn meaningful differences between them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_reviews_features = pd.read_parquet('train_reviews_features.parquet')\n",
    "train_reviews_tokens = pd.read_parquet('train_reviews_tokens.parquet')\n",
    "train_matches = pd.read_csv('train_matches.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get embeddings for K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'sentence-transformers/all-MiniLM-L12-v2'\n",
    "model = AutoModel.from_pretrained(model_name).to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "def get_review_embeddings(train_reviews_tokens, batch_size=32, max_length=128):\n",
    "    \"\"\"\n",
    "    Get embeddings for reviews using the MiniLM model\n",
    "    Args:\n",
    "        train_reviews_tokens: dataframe with tokenized reviews\n",
    "        batch_size: batch size\n",
    "        max_length: maximum length of the review\n",
    "    Returns:\n",
    "        embeddings: list of embeddings for reviews\n",
    "    \"\"\"\n",
    "    embeddings = []\n",
    "    model.eval()\n",
    "    with torch.no_grad(): \n",
    "        for i in tqdm(range(0, len(train_reviews_tokens), batch_size), total=len(train_reviews_tokens)//batch_size):\n",
    "            batch = train_reviews_tokens.iloc[i:i + batch_size]\n",
    "            input_ids = [torch.tensor(ids) for ids in batch['input_ids'].tolist()]\n",
    "            attention_mask = [torch.tensor(mask) for mask in batch['attention_mask'].tolist()]\n",
    "\n",
    "            input_ids = pad_sequence(input_ids, batch_first=True, padding_value=0)\n",
    "            attention_mask = pad_sequence(attention_mask, batch_first=True, padding_value=0)\n",
    "\n",
    "            input_ids = input_ids[:, :max_length]\n",
    "            attention_mask = attention_mask[:, :max_length]\n",
    "\n",
    "            input_ids = input_ids.to(device)\n",
    "            attention_mask = attention_mask.to(device)\n",
    "\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            batch_embeddings = outputs.last_hidden_state.mean(dim=1).cpu().numpy()\n",
    "            embeddings.extend(batch_embeddings)\n",
    "    \n",
    "    return embeddings\n",
    "\n",
    "def create_embedding_df(train_reviews_tokens):\n",
    "    \"\"\"\n",
    "    Create dataframe with embeddings for reviews\n",
    "    Args:\n",
    "        train_reviews_tokens: dataframe with tokenized reviews\n",
    "    Returns:\n",
    "        embedding_df: dataframe with embeddings for reviews\n",
    "    \"\"\"\n",
    "    embeddings = get_review_embeddings(train_reviews_tokens)\n",
    "    embedding_df = pd.DataFrame(embeddings, columns=[f'emb_{i}' for i in range(embeddings[0].shape[0])])\n",
    "    return embedding_df\n",
    "\n",
    "embedding_df = create_embedding_df(train_reviews_tokens)\n",
    "\n",
    "train_reviews_features = train_reviews_features.reset_index(drop=True)  \n",
    "embedding_df = embedding_df.reset_index(drop=True)\n",
    "\n",
    "feature_columns = train_reviews_features.columns[2:]\n",
    "feature_and_embedding_df = pd.concat([train_reviews_features[feature_columns], embedding_df], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters = 100\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "kmeans_labels = kmeans.fit_predict(feature_and_embedding_df)\n",
    "\n",
    "train_reviews_features['kmeans_label'] = kmeans_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Groups from K-Menas and save for dataset creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_id_to_idx = {row['review_id']: idx for idx, row in train_matches.iterrows()}\n",
    "\n",
    "kmeans_groups = {}\n",
    "\n",
    "grouped = train_reviews_features.groupby('kmeans_label')\n",
    "\n",
    "for label, group in grouped:\n",
    "    review_ids_in_group = group['review_id'].tolist()\n",
    "    \n",
    "    for review_id in review_ids_in_group:\n",
    "        if review_id in review_id_to_idx:\n",
    "            index = review_id_to_idx[review_id]\n",
    "            \n",
    "            if label not in kmeans_groups:\n",
    "                kmeans_groups[label] = []\n",
    "            kmeans_groups[label].append(index)\n",
    "\n",
    "with open('kmeans_groups.pkl', 'wb') as f:\n",
    "    pickle.dump(kmeans_groups, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
